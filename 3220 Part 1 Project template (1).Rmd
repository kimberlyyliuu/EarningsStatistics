---
title: "STAT 3220 Group Project" 
author: "KHL"
fontsize: 12pt
geometry: margin=1in
urlcolor: black
output: pdf_document
header-includes:
- \usepackage{setspace}
- \usepackage{ulem}
- \onehalfspacing
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, highlight=FALSE, comment=NA, warnings=FALSE,message=FALSE)
```


```{r, include = F}
# Reading Raw Data and Subsetting
if (!sum(1,1) == 2) {
# Set Working Directory
setwd("/Users/hadleymcq/Desktop/STAT 3220/Project 1/Data for 3220")

# Storing Data in R
firstset<-read_csv("pppub20.csv")

# Subsetting desired variables
firstset<-firstset[(c("PERIDNUM", "PRDTRACE", "A_HGA", "A_SEX", "PTOT_R", "PEARNVAL", "A_MARITL", "HEA", "MIG_DIV", "PERIDNUM"))]

# Renaming Variables
colnames(firstset) <- c("IDNUM", "RACE", "H_ED", "SEX", "TOT_IN", "PEARNVAL", "MARITL", "HEA", "RES_DIV", "IDNUM_MATCHER")

# In order to merge with another dataset, we need a common grouping to match observations to, like state. Although state is not present in this dataset, it is present in another dataset pertaining to the same study, reporting on variables pertaining to household. The two sets report the same first 20 digits of the ID number, differing in the last two. The state variable may be taken from the household set, and matched to this set, which reports on the individual level. 
# i.e.
# H_IDNUM =  00000479261031911011
# PERIDNUM = 0000047926103191101101

# Storing the household set in R
secondset<-read.csv("hhpub20.csv")

# Pulling desired variables from the household set
secondset<-secondset[(c("H_IDNUM","GESTFIPS"))]

# Renaming Variables
colnames(secondset) <- c("IDNUM","STATE")

# Abbreviating the first set's ID:
firstset$IDNUM_MATCHER<-substring(firstset$IDNUM_MATCHER, 1, nchar(firstset$IDNUM_MATCHER)-2)

# Merging firstset with secondset
CensusData<-merge(firstset, secondset, by.x = "IDNUM_MATCHER", by.y = "IDNUM")

# Exporting as a .csv file for upload to GitHub
write.csv(CensusData, "CensusData.csv", row.names = FALSE)} else {
  cat("Chunk skipped; data will be loaded into environment via GitHub in the following chunk")
}
```


```{r, include = F}
# Accessing Compiled and Wrangled Data via GitHub
CensusData<-read.csv("https://raw.githubusercontent.com/kimberlyyliuu/STAT3220Project/main/CensusData.csv",header=T)
```


```{r, echo=FALSE, warning=FALSE,results=FALSE}
# Package Installation
# Tidyverse 
if (!requireNamespace("tidyverse", quietly = T)) install.packages("tidyverse")
library(tidyverse)
if (!requireNamespace("readr", quietly = T)) install.packages("readr")
library(readr)
```


```{r, include = T}
# TO SEE OUTPUTS OF CHUNK, CHANGE "INCLUDE = F" TO "INCLUDE = T"
# EDA: 
head(CensusData)

## Using histograms
hist(CensusData$STATE)
# Evenly distributed; do not treat as an explanatory variable
hist(CensusData$RACE)
# heaviest reporting on race 1 -/> probably shouldn't build model with race as explanatory because of this biased reporting
hist(CensusData$H_ED)
# sufficient as explanatory
hist(CensusData$SEX)
# sufficient as explanatory; relatively equal reporting
hist(CensusData$TOT_IN)
# questionable significance, seems to be binned in a way that ambiguates data
hist(CensusData$PEARNVAL)
# Good response variable; examine any potential categorization in reporting
hist(CensusData$MARITL)
# Look into codebook to find why this isn't binary
hist(CensusData$HEA)
# Good explanatory 
hist(CensusData$RES_DIV)
# Oddly distributed; bimodal with odd pattern (valley immediately adjacent to mode)

# Are any of the variables reported purely quantitatively? 

more_than_50_unique <- sapply(CensusData, function(column) {
  if(is.numeric(column)) { 
    return(length(unique(column)) > 50) 
  } else {
    return(FALSE)
  }
})
quantitative_vars <- names(more_than_50_unique[more_than_50_unique])
print(quantitative_vars)
```


```{r, include = F}
# \sout{How to merge this data with another set?} *This chunk is unnecessary; preserved for potentially useful code*
# Group by a variable common to another data set.
# But what variable? 
# Whatever variable we group by, we will be limited by the number of unique responses to that variable; for example, if we group by gender, then we will only have 2 observations to perform regression analysis on. Ideally, we should have at least 30-50. 
# To find out the number of unique responses for each variable: 
number_of_responses <- sapply(CensusData, function(column) {
  if(is.numeric(column)) { 
    return(length(unique(column))) 
  } else {
    return(FALSE)
  }
})
print(number_of_responses)
```


```{r, include = F}
# \sout{Continued GroupBy Exploration} *This chunk is unnecessary; preserved for potentially useful code*
# RACE (25), TOT_IN (42), and maybe H_ED (17) seem like viable variables to group by. 
# Extracting these variables for further analysis: 
potentialGroupBy<-CensusData[c("RACE", "TOT_IN", "H_ED")]
results<-list()
for (i in names(potentialGroupBy)[1:3]) {
  counts<-potentialGroupBy |>
           group_by(.data[[i]]) |>
           summarize(Count=n())
  results[[i]] <- counts
}
results$RACE
results$TOT_IN
results$H_ED

# \sout{TOT_IN appears to be the best variable to group by statistically. It is the most evenly distributed of the three variables; each unique response has approximately the same number count. RACE is highly differential in its reporting. H_ED is intermediate of the two, and could function as a backup. 

# However, if another dataset possesses identical variables, it may be appended directly to the end, simply adding more observations. No redefinition of an observation would be necessary; individuals may still be the unit of an observation.}

# Amended: State variable will be used for grouping. It provides 51 observations (states+DC). Data from every state and DC is present. 

```

Potential variables in another Dataset to look for, grouped by state: - Average number of hours worked by a full time employee in a week in that state
- Average number of a children parented by a person in that state
- average employee age in that state
- Unemployment rate of that state

```{r}
# Constructing the a dataset reporting unemployment rates by state in 2020 from the BLS website
StatesbyFIPS<- c(1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,seq(19,42,by=1),seq(44,51,by=1), 53,54,55,56)
UNEMP_RATE<-c(6.4,8.3,7.8,6.2,10.1,6.8,7.9,7.5,7.9,8.1,6.5,11.7,5.5,9.3,7.3,5.2,5.8,6.5,8.6,5.1,6.5,9.4,10.0,6.3,8.0,6.1,5.8,4.3,13.5,6.7,9.4,7.9,9.8,7.2,5.0,8.2,6.3,7.6,8.9,9.2,6.0,4.2,7.5,7.7,4.8,5.7,6.5,8.5,8.2,6.4,5.9)

# Merge the two vectors
UnemploymentRates<-data.frame(StatesbyFIPS, UNEMP_RATE)

#Merge the new dataset, UnemploymentRates, with the CensusData
compiledData<-merge(CensusData, UnemploymentRates, by.x= "STATE", by.y = "StatesbyFIPS")

#Average Family Size by Stateq
```


Redefining Observations to be the State: 
```{r}
potentialGroupBy<-CensusData[c("RACE", "TOT_IN", "H_ED")]
results<-list()
for (i in names(potentialGroupBy)[1:3]) {
  counts<-potentialGroupBy |>
           group_by(.data[[i]]) |>
           summarize(Count=n())
  results[[i]] <- counts
}

averaged<-compiledData
results<-list()
for (i in names(averaged)) {
  response<-averaged |>
    group_by(STATE) |>
    summarize(mean(i))
  results[[i]]<-response
}
 
for(i in colnames(compiledData[3:12])) {
  as.numeric(compiledData$i)
}

grouped<-for (i in colnames(compiledData[8])) {
compiledData |>
  group_by(STATE) |>
  summarise(mean(PEARNVAL))
}
grouped


compiledState<-  compiledData |>
    group_by(STATE) |>
    summarise(PEARNVAL_MEAN = mean(PEARNVAL)) 
compiledState[,3]<- compiledData |>
    group_by(STATE) |>
    summarise(HEA_mean = mean(HEA)) 

compiledData |>
  group-by(STATE)



```

\newpage 

# Pledege
Please type your names in the appropriate space below. Failing to do so will result in a 0 on this assignment.

"We have neither given nor received unauthorized help on this assignment"

- Member 1: Kimberly Liu
- Member 2: Hadley McQuerrey
- Member 3: Luke Schueuer 
- Member 4:

\newpage

## Background

## Data Description

## Exploratory Data Analysis

```{r, echo=FALSE}
## Use this setting of Code chunk for any plots you wish to make
## Refer to the Rmarkdown guide for sizing informaiton on your plots
```


```{r, echo=FALSE, warning=FALSE,results=FALSE}
## Use this chunk to compute any summary statistics that you want to use
## in your conclusions. 
## These will not print in your report
```

## Conclusion

\newpage

## Appendix A: Data Dictionary

| Race | RACE | Desc |
| Highest Education | H_ED | Desc |
| Gender | SEX | Desc |
| Total Household Income | TOT_IN | Desc | 
| Total Personal Earnings | PEARNVAL | Desc | 
| Marital Status | MARITL | Desc |
| Health Status | HEA | Desc | 
| Previous Year of Residence | RES_DIV | Desc |

\newpage
## Appendix B: Data Rows
```{r, echo=FALSE}
head(compiledData)
```

\newpage
## Appendix C: References

### Background
1. List your background citations here.

### Data
1. List your data citations here
Codebook for 2020: https://www2.census.gov/programs-surveys/cps/datasets/2020/march/ASEC2020ddl_pub_full.pdf 
Download for 2020: https://www.census.gov/data/datasets/2020/demo/cps/cps-asec-2020.html

2020 Unemployment Rates: https://www.bls.gov/lau/lastrk20.htm 