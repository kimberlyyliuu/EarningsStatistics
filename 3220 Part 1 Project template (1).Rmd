---
title: "STAT 3220 Group Project" 
author: "KHL"
fontsize: 12pt
geometry: margin=1in
urlcolor: black
output: pdf_document
header-includes:
- \usepackage{setspace}
- \onehalfspacing
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, highlight=FALSE, comment=NA, warnings=FALSE,message=FALSE)
```

```{r, echo=FALSE, warning=FALSE,results=FALSE}
# Use this space to load in packages
  # Data
CensusData <- read.csv("https://raw.githubusercontent.com/kimberlyyliuu/STAT3220Project/main/2020CensusDataSet.csv", header = T)
  # Tidyverse (for manipulation)
install.packages("tidyverse")
library(tidyverse)

```

EDA: 
```{r}
head(CensusData)

## Using histograms
hist(CensusData$Race)
# heaviest reporting on race 1 -/> probably shoudln't build model with race as explanatory because of this biased reporting
hist(CensusData$Highest_Education)
# sufficient as explanatory
hist(CensusData$Gender)
# sufficient as explanatory; relatively equal reporting
hist(CensusData$PTOT_R)
# questionable significance, seems to be binned in a way that ambiguates data
hist(CensusData$PEARNVAL)
# Good response variable
hist(CensusData$A_MARITL)
# Look into codebook to find why this isn't binary
hist(CensusData$HEA)
# Good expalantory 
hist(CensusData$MIG_DIV)
# Oddly distributed; bimodal with odd pattern (valley immediately adjacent to mode)

# Are any of the variables reported purely quantitatively? 

more_than_50_unique <- sapply(CensusData, function(column) {
  if(is.numeric(column)) { 
    return(length(unique(column)) > 50) 
  } else {
    return(FALSE)
  }
})
quantitative_vars <- names(more_than_50_unique[more_than_50_unique])
print(quantitative_vars)
```

How to merge this data with another set? 
```{r}
# Group by a variable common to another data set.
# But what variable? 
# Whatever variable we group by, we will be limited by the number of unique responses to that variable; for example, if we group by gender, then we will only have 2 observations to perform regression analysis on. Ideally, we should have at least 30-50. 
# To find out the number of unique responses for each variable: 
number_of_responses <- sapply(CensusData, function(column) {
  if(is.numeric(column)) { 
    return(length(unique(column))) 
  } else {
    return(FALSE)
  }
})
print(number_of_responses)
```
```{r}
# Race (25), PTOT_R (42), and maybe Highest_Education (17) seem like viable variables to group by. 
# Extracting these variables for further analysis: 
potentialGroupBy<-CensusData[c("Race", "PTOT_R", "Highest_Education")]
results<-list()
for (i in names(potentialGroupBy)[1:3]) {
  counts<-potentialGroupBy |>
           group_by(.data[[i]]) |>
           summarize(Count=n())
  results[[i]] <- counts
}
results$Race
results$PTOT_R
results$Highest_Education
```
PTOT_R appears to be the best variable to group by statistically. It is the most evenly distributed of the three variables; each unique response has approximately the same number count. Race is highly differential in its reporting. Higher education is intermediate of the two, and could function as a backup. 


\newpage 

# Pledege
Please type your names in the appropriate space below. Failing to do so will result in a 0 on this assignment.

"We have neither given nor received unauthorized help on this assignment"

- Member 1: Kimberly Liu
- Member 2: Hadley McQuerrey
- Member 3: Luke Schuerer 
- Member 4:

\newpage

## Background

## Data Description

## Exploratory Data Analysis

```{r, echo=FALSE}
## Use this setting of Code chunk for any plots you wish to make
## Refer to the Rmarkdown guide for sizing informaiton on your plots
```


```{r, echo=FALSE, warning=FALSE,results=FALSE}
## Use this chunk to compute any summary statistics that you want to use
## in your conclusions. 
## These will not print in your report
```

## Conclusion

\newpage

## Appendix A: Data Dictionary

|Variable Name|Abbreviated Name|Description|
|:----:|:----:|:----:|
|  |  |    |

\newpage
## Appendix B: Data Rows
```{r, echo=FALSE}
# Use head() function to output first several rows

```

\newpage
## Appendix C: References

### Background
1. List your background citations here.

### Data
1. List your data citations here
